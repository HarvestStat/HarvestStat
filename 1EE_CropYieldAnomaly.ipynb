{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5270d915",
   "metadata": {},
   "source": [
    "# Calculate yield anomalies and plot them\n",
    "- Script to take the processed crop yield data and calculate crop yield anomalies. The script calculates three different types of anomalies to enable sensitivity analyses, and writes out new objects accordingly\n",
    "- In a second step these yield anomalies are written out to gridded netCDF objects for ease of use in other applications as this is the standard format for other gridded yield products\n",
    "- These yield anomalies are finally also written to the original dataframe so that the data can be accessed either as a dataframe or as a gridded product\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb34a88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "from scipy import ndimage\n",
    "import netCDF4\n",
    "import os, json\n",
    "import warnings\n",
    "import regionmask\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from tools import save_hdf\n",
    "from tools import CreateLinkAdmin\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f113fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a moving average function\n",
    "def moving_average(a, smooth) :\n",
    "    n=smooth*2+1\n",
    "    ret = np.cumsum(a, dtype=float)\n",
    "    ret[n:] = ret[n:] - ret[:-n]\n",
    "    return ret[n - 1:] / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "380f7b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in the crop yield data\n",
    "df = pd.read_hdf('./data/crop/adm_crop_production_ALL.hdf')\n",
    "#read in the FEWS admins\n",
    "shape = gpd.read_file('./data/shapefile/adm_current.shp').to_crs(\"EPSG:4326\")\n",
    "#merge the two\n",
    "df = df.merge(shape[['FNID','ADMIN0','ADMIN1','ADMIN2']], left_on='fnid', right_on='FNID')\n",
    "df = df.rename(columns={'ADMIN1':'admin1','ADMIN2':'admin2','season_name':'season'})\n",
    "df['admin'] = df['fnid'].apply(lambda x: x[2:8])\n",
    "cols = ['fnid','country','admin','admin1','admin2','product','season','harvest_month','harvest_year','indicator','value']\n",
    "df = df[cols]\n",
    "\n",
    "#read in the crop yield data at resolution adm1 and adm0\n",
    "df0 = pd.read_hdf('./data/crop/adm0_crop_production_ALL.hdf')\n",
    "df1 = pd.read_hdf('./data/crop/adm1_crop_production_ALL.hdf')\n",
    "#read in the FEWS admins\n",
    "shape1 = gpd.read_file('./data/shapefile/adm1_current.shp').to_crs(\"EPSG:4326\")\n",
    "#merge the two admin 1s\n",
    "df1 = df1.merge(shape1[['FNID','ADMIN0','ADMIN1','ADMIN2']], left_on='fnid', right_on='FNID')\n",
    "df1 = df1.rename(columns={'ADMIN1':'admin1','ADMIN2':'admin2','season_name':'season'})\n",
    "df1['admin'] = df1['fnid'].apply(lambda x: x[2:8])\n",
    "cols = ['fnid','country','admin','admin1','product','season','harvest_month','harvest_year','indicator','value']\n",
    "df1 = df1[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5616c9",
   "metadata": {},
   "source": [
    "### Calculate anomalies and grid\n",
    "Below is the main portion of the script, where anomalies are calculated and written out as both a table and as a gridded netCDF product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03561753",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (963293841.py, line 36)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [4]\u001b[0;36m\u001b[0m\n\u001b[0;31m    'South Africa':['Maize (White)':'Summer']},\u001b[0m\n\u001b[0m                                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#use FNIDs and years to create an empty dataframe\n",
    "fnids = df.fnid.unique()\n",
    "fnids1 = df1.fnid.unique()\n",
    "yrs = np.sort(df.harvest_year.unique())\n",
    "dfEmpty = pd.DataFrame(columns = yrs, index=fnids,dtype=float)\n",
    "dfEmpty1 = pd.DataFrame(columns = yrs, index=fnids1,dtype=float)\n",
    "\n",
    "#get a table of FNIDs and geometries\n",
    "fnGeos = shape[['FNID','geometry']].drop_duplicates()\n",
    "fnGeos.set_index('FNID',inplace=True)\n",
    "\n",
    "#get a table of FNIDs and geometries for admin 1\n",
    "fnGeos1 = shape1[['FNID','geometry']].drop_duplicates()\n",
    "fnGeos1.set_index('FNID',inplace=True)\n",
    "\n",
    "#make an empty grid\n",
    "lon = np.arange(-20,55,0.25)\n",
    "lat = np.arange(40,-40,-0.25)\n",
    "\n",
    "cps = {\n",
    "    'maize1':{'Somalia':['Maize','Deyr'],\n",
    "            'Malawi':['Maize','Main'],\n",
    "            'Kenya':['Maize','Short'],\n",
    "            'Burkina Faso':['Maize','Main'],\n",
    "            'Mali':['Maize','Main'],\n",
    "            'Chad':['Maize','Main'],\n",
    "            'South Africa':['Maize (Yellow)','Summer'],\n",
    "            'Niger':['Maize','Main season'],\n",
    "            'Zambia':['Maize','Annual'],\n",
    "             'Angola':['Maize','Main'],\n",
    "              'Mozambique':['Maize','Main harvest']\n",
    "             },\n",
    "    \n",
    "    'maize2':{'Somalia':['Maize','Gu'],\n",
    "            'Kenya':['Maize','Long'],\n",
    "             'South Africa':['Maize (White)':'Summer']},\n",
    "    \n",
    "    'wheat':{'Kenya':['Wheat','Annual'],\n",
    "            'Mali':['Wheat','Main'],\n",
    "            'Chad':['Wheat','Main'],\n",
    "            'South Africa':['Wheat','Winter']}\n",
    "}\n",
    "\n",
    "dfPrd = dfEmpty.copy()\n",
    "dfArea = dfEmpty.copy()\n",
    "dfYld = dfEmpty.copy()\n",
    "dfYldGauAbs = dfEmpty.copy()\n",
    "dfYldSm5 = dfEmpty.copy()\n",
    "dfYldGau = dfEmpty.copy()\n",
    "dfPrdGau = dfEmpty.copy()\n",
    "dfAreaGau = dfEmpty.copy()\n",
    "\n",
    "dfPrd1 = dfEmpty1.copy()\n",
    "dfArea1 = dfEmpty1.copy()\n",
    "dfYld1 = dfEmpty1.copy()\n",
    "dfYldGauAbs1 = dfEmpty1.copy()\n",
    "dfYldSm51 = dfEmpty1.copy()\n",
    "dfYldGau1 = dfEmpty1.copy()\n",
    "dfPrdGau1 = dfEmpty1.copy()\n",
    "dfAreaGau1 = dfEmpty1.copy()\n",
    "\n",
    "dfPrd0 = dfEmpty.copy()\n",
    "dfArea0 = dfEmpty.copy()\n",
    "dfYld0 = dfEmpty.copy()\n",
    "dfYldGauAbs0 = dfEmpty.copy()\n",
    "dfYldSm50 = dfEmpty.copy()\n",
    "dfYldGau0 = dfEmpty.copy()\n",
    "dfPrdGau0 = dfEmpty.copy()\n",
    "dfAreaGau0 = dfEmpty.copy()\n",
    "\n",
    "for icr in ['maize1','maize2','wheat']:\n",
    "    ncPath = '/Users/wanders7/Documents/Code/Project/NASA_GSCD/gscd/data/gridded/admFull_'+icr+'.nc'\n",
    "    ncf = netCDF4.Dataset(ncPath,'w',format='NETCDF4')\n",
    "    #create dimensions                            \n",
    "    ncf.createDimension('lon',lon.size)\n",
    "    ncf.createDimension('lat',lat.size)\n",
    "    ncf.createDimension('yr',yrs.size)\n",
    "    #create variables\n",
    "    ncf.createVariable('latitude','f4',('lat'))\n",
    "    ncf.createVariable('longitude','f4',('lon'))\n",
    "    ncf.createVariable('year','i8',('yr'))\n",
    "    #fill variables lat/lon\n",
    "    ncf.variables['latitude'][:]=lat\n",
    "    ncf.variables['longitude'][:]=lon    \n",
    "    ncf.variables['year'][:]=yrs\n",
    "    #create the yield variables and objects\n",
    "    ncf.createVariable('yieldAnom_pct','f4',('yr','lat','lon'))\n",
    "    ncf.createVariable('prodAnom_pct','f4',('yr','lat','lon'))\n",
    "    ncf.createVariable('areaAnom_pct','f4',('yr','lat','lon'))\n",
    "    ncf.createVariable('yieldAnom_abs','f4',('yr','lat','lon'))\n",
    "    ncf.createVariable('yield','f4',('yr','lat','lon'))\n",
    "    ncf.createVariable('production','f4',('yr','lat','lon'))\n",
    "    ncf.createVariable('area','f4',('yr','lat','lon'))\n",
    "\n",
    "    ncPath1 = '/Users/wanders7/Documents/Code/Project/NASA_GSCD/gscd/data/gridded/adm1_'+icr+'.nc'\n",
    "    nc1 = netCDF4.Dataset(ncPath1,'w',format='NETCDF4')\n",
    "    #create dimensions                            \n",
    "    nc1.createDimension('lon',lon.size)\n",
    "    nc1.createDimension('lat',lat.size)\n",
    "    nc1.createDimension('yr',yrs.size)\n",
    "    #create variables\n",
    "    nc1.createVariable('latitude','f4',('lat'))\n",
    "    nc1.createVariable('longitude','f4',('lon'))\n",
    "    nc1.createVariable('year','i8',('yr'))\n",
    "    #fill variables lat/lon\n",
    "    nc1.variables['latitude'][:]=lat\n",
    "    nc1.variables['longitude'][:]=lon    \n",
    "    nc1.variables['year'][:]=yrs\n",
    "    #create the yield variables and objects\n",
    "    nc1.createVariable('yieldAnom_pct','f4',('yr','lat','lon'))\n",
    "    nc1.createVariable('prodAnom_pct','f4',('yr','lat','lon'))\n",
    "    nc1.createVariable('areaAnom_pct','f4',('yr','lat','lon'))\n",
    "    nc1.createVariable('yieldAnom_abs','f4',('yr','lat','lon'))\n",
    "    nc1.createVariable('yield','f4',('yr','lat','lon'))\n",
    "    nc1.createVariable('production','f4',('yr','lat','lon'))\n",
    "    nc1.createVariable('area','f4',('yr','lat','lon'))\n",
    "    \n",
    "    area = np.ones([yrs.size,lat.size,lon.size])*np.nan\n",
    "    prd = np.ones([yrs.size,lat.size,lon.size])*np.nan\n",
    "    yld = np.ones([yrs.size,lat.size,lon.size])*np.nan\n",
    "    yldAnom = np.ones([yrs.size,lat.size,lon.size])*np.nan\n",
    "    yldAnomAbs = np.ones([yrs.size,lat.size,lon.size])*np.nan\n",
    "    prdAnom = np.ones([yrs.size,lat.size,lon.size])*np.nan\n",
    "    areaAnom = np.ones([yrs.size,lat.size,lon.size])*np.nan\n",
    " \n",
    "    area1 = np.ones([yrs.size,lat.size,lon.size])*np.nan\n",
    "    prd1 = np.ones([yrs.size,lat.size,lon.size])*np.nan\n",
    "    yld1 = np.ones([yrs.size,lat.size,lon.size])*np.nan\n",
    "    yldAnom1 = np.ones([yrs.size,lat.size,lon.size])*np.nan\n",
    "    yldAnomAbs1 = np.ones([yrs.size,lat.size,lon.size])*np.nan\n",
    "    prdAnom1 = np.ones([yrs.size,lat.size,lon.size])*np.nan\n",
    "    areaAnom1 = np.ones([yrs.size,lat.size,lon.size])*np.nan\n",
    "    \n",
    "    for icx in cps[icr].keys():\n",
    "        ipx = cps[icr][icx][0]\n",
    "        isx = cps[icr][icx][1]\n",
    "        ifnds = df.loc[(df['product']==ipx)&(df.country==icx)&(df.season==isx)].fnid.unique()\n",
    "        ifnds1 = df1.loc[(df1['product']==ipx)&(df1.country==icx)&(df1.season==isx)].fnid.unique()\n",
    "        \n",
    "        for ifnx in ifnds:\n",
    "            shp = fnGeos.loc[ifnx].geometry\n",
    "            \n",
    "            ylds = df.loc[(df['product']==ipx)&(df.country==icx)&(df.season==isx)&\n",
    "                   (df.fnid==ifnx)&(df.indicator=='yield')].sort_values(by='harvest_year')\n",
    "            \n",
    "            prds = df.loc[(df['product']==ipx)&(df.country==icx)&(df.season==isx)&\n",
    "                   (df.fnid==ifnx)&(df.indicator=='production')].sort_values(by='harvest_year')\n",
    "\n",
    "            areas = df.loc[(df['product']==ipx)&(df.country==icx)&(df.season==isx)&\n",
    "                   (df.fnid==ifnx)&(df.indicator=='area')].sort_values(by='harvest_year')\n",
    "\n",
    "            #check for duplicate values, which indicates multiple production systems. \n",
    "            # If present, sum the area and production and recalculate yield\n",
    "            if ((np.size(ylds['harvest_year'][ylds['harvest_year'].duplicated()])>0)|\n",
    "                (np.size(prds['harvest_year'][prds['harvest_year'].duplicated()])>0)|\n",
    "                (np.size(areas['harvest_year'][areas['harvest_year'].duplicated()])>0)):\n",
    "                cols = ['fnid','country','admin','admin1','admin2','product','season',\n",
    "                        'harvest_month','harvest_year','indicator','value']\n",
    "                #group area and production\n",
    "                areas = areas[cols].groupby(cols[:-1]).sum()\n",
    "                prds = prds[cols].groupby(cols[:-1]).sum()\n",
    "                #reindex\n",
    "                indexCols = cols[:-2]\n",
    "                prds = prds.reset_index()\n",
    "                prds.set_index(indexCols,inplace=True)\n",
    "                areas = areas.reset_index()\n",
    "                areas.set_index(indexCols,inplace=True)\n",
    "                #write to the yield df\n",
    "                ylds = prds['value']/areas['value']\n",
    "                ylds=ylds.reset_index()\n",
    "                prds=prds.reset_index()\n",
    "                areas=areas.reset_index()\n",
    "                ylds['indicator']='yield'\n",
    "                \n",
    "            if ylds.value.size<5:\n",
    "                print('fewer than 5 years for '+ifnx+', '+ipx+', '+isx)\n",
    "                continue\n",
    "            \n",
    "            dfPrd.loc[ifnx][prds.harvest_year] = prds.value\n",
    "            dfArea.loc[ifnx][areas.harvest_year] = areas.value\n",
    "            dfYld.loc[ifnx][ylds.harvest_year] = ylds.value\n",
    "            \n",
    "            iYld = dfYld.loc[ifnx][ylds.harvest_year].values.astype(float)\n",
    "            iyldAbs = dfYld.loc[ifnx][ylds.harvest_year].values.astype(float)\n",
    "            iprdAbs = dfPrd.loc[ifnx][prds.harvest_year].values.astype(float)\n",
    "            iareaAbs = dfArea.loc[ifnx][areas.harvest_year].values.astype(float)\n",
    "\n",
    "            #To account for a missing values in locations we can drop and re-weight the remaining values by counting non-zero values        \n",
    "            yldCount = np.copy(iYld)\n",
    "            yldCount[~np.isnan(yldCount)]=1\n",
    "            yldCount[np.isnan(yldCount)]=0\n",
    "            iYld[np.isnan(iYld)]=0\n",
    "\n",
    "            prdCount = np.copy(iprdAbs)\n",
    "            prdCount[~np.isnan(prdCount)]=1\n",
    "            prdCount[np.isnan(prdCount)]=0\n",
    "            iprdAbs[np.isnan(iprdAbs)]=0\n",
    "            \n",
    "            areaCount = np.copy(iareaAbs)\n",
    "            areaCount[~np.isnan(areaCount)]=1\n",
    "            areaCount[np.isnan(areaCount)]=0\n",
    "            iareaAbs[np.isnan(iareaAbs)]=0\n",
    "            \n",
    "            #divide by the count to re-weight based on the # of values going into each smoothing filter\n",
    "            yldSm5Exp = moving_average(np.array(iYld),2)/moving_average(np.array(yldCount),2)\n",
    "            \n",
    "            yldGauExp = ndimage.gaussian_filter1d(iYld,3)/ndimage.gaussian_filter1d(yldCount,3)\n",
    "            prdGauExp = ndimage.gaussian_filter1d(iprdAbs,3)/ndimage.gaussian_filter1d(prdCount,3)\n",
    "            areaGauExp = ndimage.gaussian_filter1d(iareaAbs,3)/ndimage.gaussian_filter1d(areaCount,3)\n",
    "            \n",
    "            stYldGauAbs = (iYld-yldGauExp)\n",
    "            #percent yield anom = (yld obs - yld exp)/yld exp\n",
    "            stYldGau = (iYld-yldGauExp)/yldGauExp\n",
    "            stPrdGau = (iprdAbs-prdGauExp)/prdGauExp\n",
    "            stAreaGau = (iareaAbs-areaGauExp)/areaGauExp\n",
    "            stYldSm5 = np.array(iYld[2:-2]-yldSm5Exp)/yldSm5Exp\n",
    "            \n",
    "            #add nans back in\n",
    "            stPrdGau[np.isnan(dfPrd.loc[ifnx][prds.harvest_year].values.astype(float))]=np.nan\n",
    "            stAreaGau[np.isnan(dfArea.loc[ifnx][areas.harvest_year].values.astype(float))]=np.nan\n",
    "            stYldGau[np.isnan(dfYld.loc[ifnx][ylds.harvest_year].values.astype(float))]=np.nan\n",
    "            stYldSm5[np.isnan(dfYld.loc[ifnx][ylds.harvest_year].values[2:-2].astype(float))]=np.nan\n",
    "            stYldGauAbs[np.isnan(dfYld.loc[ifnx][ylds.harvest_year].values.astype(float))]=np.nan\n",
    "            \n",
    "            #write the empty data frames\n",
    "            dfYldGauAbs.loc[ifnx][ylds.harvest_year.values] = stYldGauAbs\n",
    "            dfYldGau.loc[ifnx][ylds.harvest_year.values] = stYldGau\n",
    "            dfPrdGau.loc[ifnx][prds.harvest_year.values] = stPrdGau\n",
    "            dfAreaGau.loc[ifnx][areas.harvest_year.values] = stAreaGau\n",
    "            dfYldSm5.loc[ifnx][ylds.harvest_year.values][2:-2] = stYldSm5\n",
    "            \n",
    "            #find the location mask\n",
    "            msk = np.array(regionmask.Regions([fnGeos.loc[ifnx].geometry]).mask(lon,lat))\n",
    "            #assign the yield time series to the relevant grid points based on the mask\n",
    "            prdAnom.T[msk.T==0,...] = dfPrdGau.loc[ifnx].values\n",
    "            areaAnom.T[msk.T==0,...] = dfAreaGau.loc[ifnx].values\n",
    "            yldAnom.T[msk.T==0,...] = dfYldGau.loc[ifnx].values\n",
    "            yldAnomAbs.T[msk.T==0,...] = dfYldGauAbs.loc[ifnx].values\n",
    "            \n",
    "            yld.T[msk.T==0,...] = dfYld.loc[ifnx].values\n",
    "            prd.T[msk.T==0,...] = dfPrd.loc[ifnx].values\n",
    "            area.T[msk.T==0,...] = dfArea.loc[ifnx].values \n",
    "            \n",
    "            #Take the gaussian yield anomalies and write them to the original dataframe\n",
    "            yldAnomGauDF = ylds.copy(deep=True) #copy the yields\n",
    "            yldAnomGauDF['value']= np.nan #set values to nan\n",
    "            yldAnomGauDF['value']= stYldGau#write in the new values\n",
    "            yldAnomGauDF['indicator'] = 'frac_yld_anom_gauss'\n",
    "            prdAnomGauDF = prds.copy(deep=True) #copy the yields\n",
    "            prdAnomGauDF['value']= np.nan #set values to nan\n",
    "            prdAnomGauDF['value']= stPrdGau#write in the new values\n",
    "            prdAnomGauDF['indicator'] = 'frac_prd_anom_gauss'\n",
    "            areaAnomGauDF = areas.copy(deep=True) #copy the yields\n",
    "            areaAnomGauDF['value']= np.nan #set values to nan\n",
    "            areaAnomGauDF['value']= stAreaGau#write in the new values\n",
    "            areaAnomGauDF['indicator'] = 'frac_area_anom_gauss'\n",
    "            df = df.append(areaAnomGauDF).append(prdAnomGauDF).append(yldAnomGauDF)\n",
    "\n",
    "        for ifnx in ifnds1:\n",
    "            shp = fnGeos1.loc[ifnx].geometry\n",
    "            \n",
    "            ylds1 = df1.loc[(df1['product']==ipx)&(df1.country==icx)&(df1.season==isx)&\n",
    "                   (df1.fnid==ifnx)&(df1.indicator=='yield')].sort_values(by='harvest_year')\n",
    "            \n",
    "            prds1 = df1.loc[(df1['product']==ipx)&(df1.country==icx)&(df1.season==isx)&\n",
    "                   (df1.fnid==ifnx)&(df1.indicator=='production')].sort_values(by='harvest_year')\n",
    "\n",
    "            areas1 = df1.loc[(df1['product']==ipx)&(df1.country==icx)&(df1.season==isx)&\n",
    "                   (df1.fnid==ifnx)&(df1.indicator=='area')].sort_values(by='harvest_year')\n",
    "\n",
    "            #check for duplicate values, which indicates multiple production systems. \n",
    "            # If present, sum the area and production and recalculate yield\n",
    "            if ((np.size(ylds1['harvest_year'][ylds1['harvest_year'].duplicated()])>0)|\n",
    "                (np.size(prds1['harvest_year'][prds1['harvest_year'].duplicated()])>0)|\n",
    "                (np.size(areas1['harvest_year'][areas1['harvest_year'].duplicated()])>0)):\n",
    "                cols = ['fnid','country','admin','admin1','product','season',\n",
    "                        'harvest_month','harvest_year','indicator','value']\n",
    "                #group area and production\n",
    "                areas1 = areas1[cols].groupby(cols[:-1]).sum()\n",
    "                prds1 = prds1[cols].groupby(cols[:-1]).sum()\n",
    "                #reindex\n",
    "                indexCols = cols[:-2]\n",
    "                prds1 = prds1.reset_index()\n",
    "                prds1.set_index(indexCols,inplace=True)\n",
    "                areas1 = areas1.reset_index()\n",
    "                areas1.set_index(indexCols,inplace=True)\n",
    "                #write to the yield df\n",
    "                ylds1 = prds1['value']/areas1['value']\n",
    "                ylds1=ylds1.reset_index()\n",
    "                prds1=prds1.reset_index()\n",
    "                areas1=areas1.reset_index()\n",
    "                ylds1['indicator']='yield'\n",
    "                \n",
    "            if ylds1.value.size<5:\n",
    "                print('fewer than 5 years for '+ifnx+', '+ipx+', '+isx)\n",
    "                continue\n",
    "            \n",
    "            dfPrd1.loc[ifnx][prds1.harvest_year] = prds1.value\n",
    "            dfArea1.loc[ifnx][areas1.harvest_year] = areas1.value\n",
    "            dfYld1.loc[ifnx][ylds1.harvest_year] = ylds1.value\n",
    "            \n",
    "            iYld1 = dfYld1.loc[ifnx][ylds1.harvest_year].values.astype(float)\n",
    "            iyldAbs1 = dfYld1.loc[ifnx][ylds1.harvest_year].values.astype(float)\n",
    "            iprdAbs1 = dfPrd1.loc[ifnx][prds1.harvest_year].values.astype(float)\n",
    "            iareaAbs1 = dfArea1.loc[ifnx][areas1.harvest_year].values.astype(float)\n",
    "\n",
    "            #To account for a missing values in locations we can drop and re-weight the remaining values by counting non-zero values        \n",
    "            yldCount1 = np.copy(iYld1)\n",
    "            yldCount1[~np.isnan(yldCount1)]=1\n",
    "            yldCount1[np.isnan(yldCount1)]=0\n",
    "            iYld1[np.isnan(iYld1)]=0\n",
    "\n",
    "            prdCount1 = np.copy(iprdAbs1)\n",
    "            prdCount1[~np.isnan(prdCount1)]=1\n",
    "            prdCount1[np.isnan(prdCount1)]=0\n",
    "            iprdAbs1[np.isnan(iprdAbs1)]=0\n",
    "            \n",
    "            areaCount1 = np.copy(iareaAbs1)\n",
    "            areaCount1[~np.isnan(areaCount1)]=1\n",
    "            areaCount1[np.isnan(areaCount1)]=0\n",
    "            iareaAbs1[np.isnan(iareaAbs1)]=0\n",
    "            \n",
    "            #divide by the count to re-weight based on the # of values going into each smoothing filter\n",
    "            yldSm5Exp1 = moving_average(np.array(iYld1),2)/moving_average(np.array(yldCount1),2)\n",
    "            \n",
    "            yldGauExp1 = ndimage.gaussian_filter1d(iYld1,3)/ndimage.gaussian_filter1d(yldCount1,3)\n",
    "            prdGauExp1 = ndimage.gaussian_filter1d(iprdAbs1,3)/ndimage.gaussian_filter1d(prdCount1,3)\n",
    "            areaGauExp1 = ndimage.gaussian_filter1d(iareaAbs1,3)/ndimage.gaussian_filter1d(areaCount1,3)\n",
    "            \n",
    "            stYldGauAbs1 = (iYld1-yldGauExp1)\n",
    "            #percent yield anom = (yld obs - yld exp)/yld exp\n",
    "            stYldGau1 = (iYld1-yldGauExp1)/yldGauExp1\n",
    "            stPrdGau1 = (iprdAbs1-prdGauExp1)/prdGauExp1\n",
    "            stAreaGau1 = (iareaAbs1-areaGauExp1)/areaGauExp1\n",
    "            stYldSm51 = np.array(iYld1[2:-2]-yldSm5Exp1)/yldSm5Exp1\n",
    "            \n",
    "            #add nans back in\n",
    "            stPrdGau1[np.isnan(dfPrd1.loc[ifnx][prds1.harvest_year].values.astype(float))]=np.nan\n",
    "            stAreaGau1[np.isnan(dfArea1.loc[ifnx][areas1.harvest_year].values.astype(float))]=np.nan\n",
    "            stYldGau1[np.isnan(dfYld1.loc[ifnx][ylds1.harvest_year].values.astype(float))]=np.nan\n",
    "            stYldSm51[np.isnan(dfYld1.loc[ifnx][ylds1.harvest_year].values[2:-2].astype(float))]=np.nan\n",
    "            stYldGauAbs1[np.isnan(dfYld1.loc[ifnx][ylds1.harvest_year].values.astype(float))]=np.nan\n",
    "            \n",
    "            #write the empty data frames\n",
    "            dfYldGauAbs1.loc[ifnx][ylds1.harvest_year.values] = stYldGauAbs1\n",
    "            dfYldGau1.loc[ifnx][ylds1.harvest_year.values] = stYldGau1\n",
    "            dfPrdGau1.loc[ifnx][prds1.harvest_year.values] = stPrdGau1\n",
    "            dfAreaGau1.loc[ifnx][areas1.harvest_year.values] = stAreaGau1\n",
    "            dfYldSm51.loc[ifnx][ylds1.harvest_year.values][2:-2] = stYldSm51\n",
    "            \n",
    "            #find the location mask\n",
    "            msk = np.array(regionmask.Regions([fnGeos1.loc[ifnx].geometry]).mask(lon,lat))\n",
    "            #assign the yield time series to the relevant grid points based on the mask\n",
    "            prdAnom1.T[msk.T==0,...] = dfPrdGau1.loc[ifnx].values\n",
    "            areaAnom1.T[msk.T==0,...] = dfAreaGau1.loc[ifnx].values\n",
    "            yldAnom1.T[msk.T==0,...] = dfYldGau1.loc[ifnx].values\n",
    "            yldAnomAbs1.T[msk.T==0,...] = dfYldGauAbs1.loc[ifnx].values\n",
    "            \n",
    "            yld1.T[msk.T==0,...] = dfYld1.loc[ifnx].values\n",
    "            prd1.T[msk.T==0,...] = dfPrd1.loc[ifnx].values\n",
    "            area1.T[msk.T==0,...] = dfArea1.loc[ifnx].values \n",
    "            \n",
    "            #Take the gaussian yield anomalies and write them to the original dataframe\n",
    "            yldAnomGauDF1 = ylds1.copy(deep=True) #copy the yields\n",
    "            yldAnomGauDF1['value']= np.nan #set values to nan\n",
    "            yldAnomGauDF1['value']= stYldGau1 #write in the new values\n",
    "            yldAnomGauDF1['indicator'] = 'frac_yld_anom_gauss'\n",
    "            prdAnomGauDF1 = prds1.copy(deep=True) #copy the yields\n",
    "            prdAnomGauDF1['value']= np.nan #set values to nan\n",
    "            prdAnomGauDF1['value']= stPrdGau1 #write in the new values\n",
    "            prdAnomGauDF1['indicator'] = 'frac_prd_anom_gauss'\n",
    "            areaAnomGauDF1 = areas1.copy(deep=True) #copy the yields\n",
    "            areaAnomGauDF1['value']= np.nan #set values to nan\n",
    "            areaAnomGauDF1['value']= stAreaGau1 #write in the new values\n",
    "            areaAnomGauDF1['indicator'] = 'frac_area_anom_gauss'\n",
    "            df1 = df1.append(areaAnomGauDF1).append(prdAnomGauDF1).append(yldAnomGauDF1)\n",
    "            \n",
    "    #write the yield objects into the netCDF\n",
    "    ncf['yield'][:] = yld\n",
    "    ncf['production'][:] = prd\n",
    "    ncf['area'][:] = area\n",
    "    ncf['yieldAnom_pct'][:] = yldAnom\n",
    "    ncf['prodAnom_pct'][:] = prdAnom\n",
    "    ncf['areaAnom_pct'][:] = areaAnom\n",
    "    ncf['yieldAnom_abs'][:] = yldAnomAbs\n",
    "    \n",
    "    ncf.close();del ncf\n",
    "    \n",
    "    #write the yield objects into the netCDF\n",
    "    nc1['yield'][:] = yld1\n",
    "    nc1['production'][:] = prd1\n",
    "    nc1['area'][:] = area1\n",
    "    nc1['yieldAnom_pct'][:] = yldAnom1\n",
    "    nc1['prodAnom_pct'][:] = prdAnom1\n",
    "    nc1['areaAnom_pct'][:] = areaAnom1\n",
    "    nc1['yieldAnom_abs'][:] = yldAnomAbs1\n",
    "    \n",
    "    nc1.close();del nc1\n",
    "\n",
    "save_hdf('./data/crop/adm_crop_production_anomalies_ALL.hdf', df)\n",
    "save_hdf('./data/crop/adm1_crop_production_anomalies_ALL.hdf', df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f29ba40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
