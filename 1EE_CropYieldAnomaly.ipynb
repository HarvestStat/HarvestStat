{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5270d915",
   "metadata": {},
   "source": [
    "# Calculate yield anomalies and plot them\n",
    "- Script to take the processed crop yield data and calculate crop yield anomalies. The script calculates three different types of anomalies to enable sensitivity analyses, and writes out new objects accordingly\n",
    "- In a second step these yield anomalies are written out to gridded netCDF objects for ease of use in other applications as this is the standard format for other gridded yield products\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb34a88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "from scipy import ndimage\n",
    "import netCDF4\n",
    "import os, json\n",
    "import warnings\n",
    "import regionmask\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from tools import save_hdf\n",
    "from tools import CreateLinkAdmin\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f113fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a moving average function\n",
    "def moving_average(a, smooth) :\n",
    "    n=smooth*2+1\n",
    "    ret = np.cumsum(a, dtype=float)\n",
    "    ret[n:] = ret[n:] - ret[:-n]\n",
    "    return ret[n - 1:] / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "380f7b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in the crop yield data\n",
    "df = pd.read_hdf('./data/crop/adm_crop_production_ALL.hdf')\n",
    "#read in the FEWS admins\n",
    "shape = gpd.read_file('./data/shapefile/adm_current.shp').to_crs(\"EPSG:4326\")\n",
    "#merge the two\n",
    "df = pd.read_hdf('./data/crop/adm_crop_production_ALL.hdf')\n",
    "df = df.merge(shape[['FNID','ADMIN0','ADMIN1','ADMIN2']], left_on='fnid', right_on='FNID')\n",
    "df = df.rename(columns={'ADMIN1':'admin1','ADMIN2':'admin2','season_name':'season'})\n",
    "df['admin'] = df['fnid'].apply(lambda x: x[2:8])\n",
    "cols = ['fnid','country','admin','product','season','harvest_month','harvest_year','indicator','value']\n",
    "df = df[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5616c9",
   "metadata": {},
   "source": [
    "### Calculate anomalies and grid\n",
    "Below is the main portion of the script, where anomalies are calculated and written out as both a table and as a gridded netCDF product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03561753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fewer than 5 years for SO1990A22502, Maize, Deyr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pk/_ym78shs7tx06w00zbcwxwgc0000gp/T/ipykernel_69046/2594005666.py:178: UserWarning: No gridpoint belongs to any region. Returning an all-NaN mask.\n",
      "  msk = np.array(regionmask.Regions([fnGeos.loc[ifnx].geometry]).mask(lon,lat))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fewer than 5 years for KE2013A108, Maize, Short\n",
      "fewer than 5 years for KE2013A118, Maize, Short\n",
      "fewer than 5 years for KE2013A123, Maize, Short\n",
      "fewer than 5 years for KE2013A124, Maize, Short\n",
      "fewer than 5 years for KE2013A125, Maize, Short\n",
      "fewer than 5 years for KE2013A128, Maize, Short\n",
      "fewer than 5 years for KE2013A129, Maize, Short\n",
      "fewer than 5 years for KE2013A130, Maize, Short\n",
      "fewer than 5 years for KE2013A133, Maize, Short\n",
      "fewer than 5 years for KE2013A135, Maize, Short\n",
      "fewer than 5 years for KE2013A147, Maize, Short\n",
      "fewer than 5 years for ML2001A107, Maize, Main\n",
      "fewer than 5 years for NE2012A20516, Maize, Main season\n",
      "fewer than 5 years for NE2012A20603, Maize, Main season\n",
      "fewer than 5 years for NE2012A20607, Maize, Main season\n",
      "fewer than 5 years for NE2012A20611, Maize, Main season\n",
      "fewer than 5 years for NE2012A20614, Maize, Main season\n",
      "fewer than 5 years for NE2012A20616, Maize, Main season\n",
      "fewer than 5 years for NE2012A20805, Maize, Main season\n",
      "fewer than 5 years for NE2012A20806, Maize, Main season\n",
      "fewer than 5 years for NE2012A20204, Maize, Main season\n",
      "fewer than 5 years for NE2012A20205, Maize, Main season\n",
      "fewer than 5 years for NE2012A20210, Maize, Main season\n",
      "fewer than 5 years for SO1990A22502, Maize, Gu\n",
      "fewer than 5 years for KE2013A147, Maize, Long\n",
      "fewer than 5 years for ML2001A103, Wheat, Main\n"
     ]
    }
   ],
   "source": [
    "#use FNIDs and years to create an empty dataframe\n",
    "fnids = df.fnid.unique()\n",
    "yrs = np.sort(df.harvest_year.unique())\n",
    "dfEmpty = pd.DataFrame(columns = yrs, index=fnids,dtype=float)\n",
    "\n",
    "#get a table of FNIDs and geometries\n",
    "fnGeos = shape[['FNID','geometry']].drop_duplicates()\n",
    "fnGeos.set_index('FNID',inplace=True)\n",
    "\n",
    "#make an empty grid\n",
    "lon = np.arange(-20,55,0.1)\n",
    "lat = np.arange(40,-40,-0.1)\n",
    "\n",
    "cps = {\n",
    "    'maize1':{'Somalia':['Maize','Deyr'],\n",
    "            'Malawi':['Maize','Main'],\n",
    "            'Kenya':['Maize','Short'],\n",
    "            'Burkina Faso':['Maize','Main'],\n",
    "            'Mali':['Maize','Main'],\n",
    "            'Chad':['Maize','Main'],\n",
    "            'South Africa':['Maize (Yellow)','Summer'],\n",
    "            'Niger':['Maize','Main season'],\n",
    "            'Zambia':['Maize','Annual'],\n",
    "             'Angola':['Maize','Main'],\n",
    "              'Mozambique':['Maize','Main harvest']\n",
    "             },\n",
    "    \n",
    "    'maize2':{'Somalia':['Maize','Gu'],\n",
    "            'Kenya':['Maize','Long']},\n",
    "    \n",
    "    'wheat':{'Kenya':['Wheat','Annual'],\n",
    "            'Mali':['Wheat','Main'],\n",
    "            'Chad':['Wheat','Main'],\n",
    "            'South Africa':['Wheat','Winter']}\n",
    "}\n",
    "\n",
    "dfPrd = dfEmpty.copy()\n",
    "dfArea = dfEmpty.copy()\n",
    "dfYld = dfEmpty.copy()\n",
    "dfYldGauAbs = dfEmpty.copy()\n",
    "dfYldSm5 = dfEmpty.copy()\n",
    "dfYldGau = dfEmpty.copy()\n",
    "dfPrdGau = dfEmpty.copy()\n",
    "dfAreaGau = dfEmpty.copy()\n",
    "\n",
    "\n",
    "for icr in ['maize1','maize2','wheat']:\n",
    "    ncPath = '/Users/wanders7/Documents/Code/Project/NASA_GSCD/gscd/data/gridded/'+icr+'.nc'\n",
    "    ncf = netCDF4.Dataset(ncPath,'w',format='NETCDF4')\n",
    "    #create dimensions                            \n",
    "    ncf.createDimension('lon',lon.size)\n",
    "    ncf.createDimension('lat',lat.size)\n",
    "    ncf.createDimension('yr',yrs.size)\n",
    "    #create variables\n",
    "    ncf.createVariable('latitude','f4',('lat'))\n",
    "    ncf.createVariable('longitude','f4',('lon'))\n",
    "    ncf.createVariable('year','i8',('yr'))\n",
    "    #fill variables lat/lon\n",
    "    ncf.variables['latitude'][:]=lat\n",
    "    ncf.variables['longitude'][:]=lon    \n",
    "    ncf.variables['year'][:]=yrs\n",
    "    #create the yield variables and objects\n",
    "    ncf.createVariable('yieldAnom_pct','f4',('yr','lat','lon'))\n",
    "    ncf.createVariable('prodAnom_pct','f4',('yr','lat','lon'))\n",
    "    ncf.createVariable('areaAnom_pct','f4',('yr','lat','lon'))\n",
    "    ncf.createVariable('yieldAnom_abs','f4',('yr','lat','lon'))\n",
    "    ncf.createVariable('yield','f4',('yr','lat','lon'))\n",
    "    ncf.createVariable('production','f4',('yr','lat','lon'))\n",
    "    ncf.createVariable('area','f4',('yr','lat','lon'))\n",
    "    \n",
    "    \n",
    "    area = np.ones([yrs.size,lat.size,lon.size])*np.nan\n",
    "    prd = np.ones([yrs.size,lat.size,lon.size])*np.nan\n",
    "    yld = np.ones([yrs.size,lat.size,lon.size])*np.nan\n",
    "    yldAnom = np.ones([yrs.size,lat.size,lon.size])*np.nan\n",
    "    yldAnomAbs = np.ones([yrs.size,lat.size,lon.size])*np.nan\n",
    "    prdAnom = np.ones([yrs.size,lat.size,lon.size])*np.nan\n",
    "    areaAnom = np.ones([yrs.size,lat.size,lon.size])*np.nan\n",
    "    \n",
    "    for icx in cps[icr].keys():\n",
    "        ipx = cps[icr][icx][0]\n",
    "        isx = cps[icr][icx][1]\n",
    "        ifnds = df.loc[(df['product']==ipx)&(df.country==icx)&(df.season==isx)].fnid.unique()\n",
    "        \n",
    "        for ifnx in ifnds:\n",
    "            shp = fnGeos.loc[ifnx].geometry\n",
    "            \n",
    "            ylds = df.loc[(df['product']==ipx)&(df.country==icx)&(df.season==isx)&\n",
    "                   (df.fnid==ifnx)&(df.indicator=='yield')].sort_values(by='harvest_year')\n",
    "            \n",
    "            prds = df.loc[(df['product']==ipx)&(df.country==icx)&(df.season==isx)&\n",
    "                   (df.fnid==ifnx)&(df.indicator=='production')].sort_values(by='harvest_year')\n",
    "\n",
    "            areas = df.loc[(df['product']==ipx)&(df.country==icx)&(df.season==isx)&\n",
    "                   (df.fnid==ifnx)&(df.indicator=='area')].sort_values(by='harvest_year')\n",
    "\n",
    "            #check for duplicate values, which indicates multiple production systems. \n",
    "            # If present, sum the area and production and recalculate yield\n",
    "            if ((np.size(ylds['harvest_year'][ylds['harvest_year'].duplicated()])>0)|\n",
    "                (np.size(prds['harvest_year'][prds['harvest_year'].duplicated()])>0)|\n",
    "                (np.size(areas['harvest_year'][areas['harvest_year'].duplicated()])>0)):\n",
    "                cols = ['fnid','country','admin','product','season',\n",
    "                        'harvest_month','harvest_year','indicator','value']\n",
    "                #group area and production\n",
    "                areas = areas[cols].groupby(cols[:-1]).sum()\n",
    "                prds = prds[cols].groupby(cols[:-1]).sum()\n",
    "                #reindex\n",
    "                indexCols = cols[:-2]\n",
    "                prds = prds.reset_index()\n",
    "                prds.set_index(indexCols,inplace=True)\n",
    "                areas = areas.reset_index()\n",
    "                areas.set_index(indexCols,inplace=True)\n",
    "                #write to the yield df\n",
    "                ylds = prds['value']/areas['value']\n",
    "                ylds=ylds.reset_index()\n",
    "                prds=prds.reset_index()\n",
    "                areas=areas.reset_index()\n",
    "                ylds['indicator']='yield'\n",
    "                \n",
    "            if ylds.value.size<5:\n",
    "                print('fewer than 5 years for '+ifnx+', '+ipx+', '+isx)\n",
    "                continue\n",
    "            \n",
    "            dfPrd.loc[ifnx][prds.harvest_year] = prds.value\n",
    "            dfArea.loc[ifnx][areas.harvest_year] = areas.value\n",
    "            dfYld.loc[ifnx][ylds.harvest_year] = ylds.value\n",
    "            \n",
    "            iYld = dfYld.loc[ifnx][ylds.harvest_year].values.astype(float)\n",
    "            iyldAbs = dfYld.loc[ifnx][ylds.harvest_year].values.astype(float)\n",
    "            iprdAbs = dfPrd.loc[ifnx][prds.harvest_year].values.astype(float)\n",
    "            iareaAbs = dfArea.loc[ifnx][areas.harvest_year].values.astype(float)\n",
    "\n",
    "            #To account for a missing values in locations we can drop and re-weight the remaining values by counting non-zero values        \n",
    "            yldCount = np.copy(iYld)\n",
    "            yldCount[~np.isnan(yldCount)]=1\n",
    "            yldCount[np.isnan(yldCount)]=0\n",
    "            iYld[np.isnan(iYld)]=0\n",
    "\n",
    "            prdCount = np.copy(iprdAbs)\n",
    "            prdCount[~np.isnan(prdCount)]=1\n",
    "            prdCount[np.isnan(prdCount)]=0\n",
    "            iprdAbs[np.isnan(iprdAbs)]=0\n",
    "            \n",
    "            areaCount = np.copy(iareaAbs)\n",
    "            areaCount[~np.isnan(areaCount)]=1\n",
    "            areaCount[np.isnan(areaCount)]=0\n",
    "            iareaAbs[np.isnan(iareaAbs)]=0\n",
    "            \n",
    "            #divide by the count to re-weight based on the # of values going into each smoothing filter\n",
    "            yldSm5Exp = moving_average(np.array(iYld),2)/moving_average(np.array(yldCount),2)\n",
    "            \n",
    "            yldGauExp = ndimage.gaussian_filter1d(iYld,3)/ndimage.gaussian_filter1d(yldCount,3)\n",
    "            prdGauExp = ndimage.gaussian_filter1d(iprdAbs,3)/ndimage.gaussian_filter1d(prdCount,3)\n",
    "            areaGauExp = ndimage.gaussian_filter1d(iareaAbs,3)/ndimage.gaussian_filter1d(areaCount,3)\n",
    "            \n",
    "            stYldGauAbs = (iYld-yldGauExp)\n",
    "            #percent yield anom = (yld obs - yld exp)/yld exp\n",
    "            stYldGau = (iYld-yldGauExp)/yldGauExp\n",
    "            stPrdGau = (iprdAbs-prdGauExp)/prdGauExp\n",
    "            stAreaGau = (iareaAbs-areaGauExp)/areaGauExp\n",
    "            stYldSm5 = np.array(iYld[2:-2]-yldSm5Exp)/yldSm5Exp\n",
    "            \n",
    "            #add nans back in\n",
    "            stPrdGau[np.isnan(dfPrd.loc[ifnx][prds.harvest_year].values.astype(float))]=np.nan\n",
    "            stAreaGau[np.isnan(dfArea.loc[ifnx][areas.harvest_year].values.astype(float))]=np.nan\n",
    "            stYldGau[np.isnan(dfYld.loc[ifnx][ylds.harvest_year].values.astype(float))]=np.nan\n",
    "            stYldSm5[np.isnan(dfYld.loc[ifnx][ylds.harvest_year].values[2:-2].astype(float))]=np.nan\n",
    "            stYldGauAbs[np.isnan(dfYld.loc[ifnx][ylds.harvest_year].values.astype(float))]=np.nan\n",
    "            \n",
    "            #write the empty data frames\n",
    "            dfYldGauAbs.loc[ifnx][ylds.harvest_year.values] = stYldGauAbs\n",
    "            dfYldGau.loc[ifnx][ylds.harvest_year.values] = stYldGau\n",
    "            dfPrdGau.loc[ifnx][prds.harvest_year.values] = stPrdGau\n",
    "            dfAreaGau.loc[ifnx][areas.harvest_year.values] = stAreaGau\n",
    "            dfYldSm5.loc[ifnx][ylds.harvest_year.values][2:-2] = stYldSm5\n",
    "            \n",
    "            #find the location mask\n",
    "            msk = np.array(regionmask.Regions([fnGeos.loc[ifnx].geometry]).mask(lon,lat))\n",
    "            #assign the yield time series to the relevant grid points based on the mask\n",
    "            prdAnom.T[msk.T==0,...] = dfPrdGau.loc[ifnx].values\n",
    "            areaAnom.T[msk.T==0,...] = dfAreaGau.loc[ifnx].values\n",
    "            yldAnom.T[msk.T==0,...] = dfYldGau.loc[ifnx].values\n",
    "            yldAnomAbs.T[msk.T==0,...] = dfYldGauAbs.loc[ifnx].values\n",
    "            \n",
    "            yld.T[msk.T==0,...] = dfYld.loc[ifnx].values\n",
    "            prd.T[msk.T==0,...] = dfPrd.loc[ifnx].values\n",
    "            area.T[msk.T==0,...] = dfArea.loc[ifnx].values \n",
    "            \n",
    "            \n",
    "    #write the yield objects into the netCDF\n",
    "    ncf['yield'][:] = yld\n",
    "    ncf['production'][:] = prd\n",
    "    ncf['area'][:] = area\n",
    "    ncf['yieldAnom_pct'][:] = yldAnom\n",
    "    ncf['prodAnom_pct'][:] = prdAnom\n",
    "    ncf['areaAnom_pct'][:] = areaAnom\n",
    "    ncf['yieldAnom_abs'][:] = yldAnomAbs\n",
    "    \n",
    "    ncf.close();del ncf\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe3d332",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f676bb2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
