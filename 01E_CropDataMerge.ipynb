{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff9b9ec5-d7b5-47f9-ad7c-e1944787daf8",
   "metadata": {},
   "source": [
    "## Crop Data Merge\n",
    "- This notebook merges FDW crop data of individual countries into a single data file with cross-checking \"FNID\" and \"Name\" between FDW data and FEWS NET's Shapefile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "600a2d45-a0c1-4195-aea9-29a2612caf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from tools import save_hdf\n",
    "import json\n",
    "from tools import CreateLinkAdmin\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89731dec-8303-475a-839a-e64bd8ad6d16",
   "metadata": {},
   "source": [
    "### Merge crop data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0288e22-d877-44d6-b9cc-c3ce5885e1e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/crop/adm_crop_production_ALL.hdf is saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dlee/opt/anaconda3/envs/chafs/lib/python3.8/site-packages/geopandas/io/file.py:299: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  pd.Int64Index,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/shapefile/adm_current.shp is saved.\n"
     ]
    }
   ],
   "source": [
    "# Merge crop data\n",
    "countries_ISO = ['SO','MW','KE','BF']\n",
    "container = []\n",
    "for name in countries_ISO:\n",
    "    df = pd.read_hdf('./data/crop/adm_crop_production_%s.hdf' % name)\n",
    "    if name == 'KE':\n",
    "        # Manual editing -------------------------- #\n",
    "        # - Fill missing \"Long\" and \"short\" season records with \"Annual\" records for Kenya\n",
    "        df = df.pivot_table(index='year', columns=['fnid','country','name','product','season_name','harvest_end','indicator'], values='value')\n",
    "        annual = df.loc[:,pd.IndexSlice[:,'Kenya',:,'Maize','Annual']]\n",
    "        annual.columns = annual.columns.droplevel([1,2,3,4,5])\n",
    "        long = df.loc[:,pd.IndexSlice[:,'Kenya',:,'Maize','Long']]\n",
    "        long.columns = long.columns.droplevel([1,2,3,4,5])\n",
    "        long = long.fillna(annual)\n",
    "        df.loc[:,pd.IndexSlice[:,'Kenya',:,'Maize','Long']] = long.values\n",
    "        short = df.loc[:,pd.IndexSlice[:,'Kenya',:,'Maize','Short']]\n",
    "        short.columns = short.columns.droplevel([1,2,3,4,5])\n",
    "        short = short.fillna(annual)\n",
    "        df.loc[:,pd.IndexSlice[:,'Kenya',:,'Maize','Short']] = short.values\n",
    "        df = df.T.stack(dropna=True).reset_index().rename(columns={0:'value'})\n",
    "        # ----------------------------------------- #\n",
    "    container.append(df)\n",
    "df = pd.concat(container, axis=0).reset_index(drop=True)\n",
    "\n",
    "# Merge the latest shapefile\n",
    "shape_container = []\n",
    "path_dir = './data/shapefile/fewsnet/'\n",
    "shape_container.append(gpd.read_file(os.path.join(path_dir, 'SO_Admin2_1990.shp')))\n",
    "shape_container.append(gpd.read_file(os.path.join(path_dir, 'MW_Admin2_2003.shp')))\n",
    "shape_container.append(gpd.read_file(os.path.join(path_dir, 'KE_Admin1_2013.shp')))\n",
    "shape_container.append(gpd.read_file(os.path.join(path_dir, 'BF_Admin2_2001.shp')))\n",
    "adm_current = pd.concat(shape_container, axis=0).reset_index(drop=True)[['FNID','ADMIN0','ADMIN1','ADMIN2','geometry']]\n",
    "adm_current = adm_current.to_crs(epsg=4326)\n",
    "\n",
    "# Update FNID to the latest FEWS NET's entire shapfile FNID (if different)\n",
    "# For instance, MW2003A2 is the latest boundary in FDW data, but the FEWS NET's African ADMIN-2 shapefile contains MW2007A2 which is regarded as the same.\n",
    "# We already use this African ADMIN shapefile to EO aggregation, so here we will just modify the FDW crop data.\n",
    "adm1 = gpd.read_file('./data/shapefile/fewsnet/FEWSNET_Admin1.shp').to_crs(\"EPSG:4326\")\n",
    "adm2 = gpd.read_file('./data/shapefile/fewsnet/FEWSNET_Admin2.shp').to_crs(\"EPSG:4326\")\n",
    "# - Crop data\n",
    "fnid_new = pd.concat([adm1.FNID, adm2.FNID], axis=0).reset_index(drop=True)\n",
    "fnid_old = adm_current.FNID\n",
    "diff = fnid_old[~fnid_old.isin(fnid_new)].values\n",
    "diff_adm1 = diff[[t[7]=='1' for t in diff]]\n",
    "diff_adm2 = diff[[t[7]=='2' for t in diff]]\n",
    "old = adm_current[adm_current.FNID.isin(diff_adm1)]\n",
    "new = adm1[adm1.ADMIN0.isin(old.ADMIN0.unique())]\n",
    "link_adm1 = CreateLinkAdmin(new, old, 'ADMIN1', 'ADMIN1')[0]\n",
    "old = adm_current[adm_current.FNID.isin(diff_adm2)]\n",
    "new = adm2[adm2.ADMIN0.isin(old.ADMIN0.unique())]\n",
    "link_adm2 = CreateLinkAdmin(new, old, 'ADMIN2', 'ADMIN2')[0]\n",
    "rename_adm = {**link_adm1, **link_adm2}\n",
    "df.fnid = df.fnid.replace(rename_adm)\n",
    "# - Current shapefile\n",
    "adm1_countries = adm_current[[t[7]=='1' for t in adm_current.FNID]].ADMIN0.unique()\n",
    "adm2_countries = adm_current[[t[7]=='2' for t in adm_current.FNID]].ADMIN0.unique()\n",
    "adm_current = pd.concat([adm1[adm1.ADMIN0.isin(adm1_countries)],\n",
    "                         adm2[adm2.ADMIN0.isin(adm2_countries)],\n",
    "                        ], axis=0).sort_values(by='FNID').reset_index(drop=True)\n",
    "\n",
    "# Save files\n",
    "save_hdf('./data/crop/adm_crop_production_ALL.hdf', df)\n",
    "adm_current.to_file('./data/shapefile/adm_current.shp')\n",
    "print('%s is saved.' % './data/shapefile/adm_current.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a416889-8b7f-4caf-a4cf-0ba77401a578",
   "metadata": {},
   "source": [
    "### Export to Public: [Weston's Google Drive](https://drive.google.com/drive/folders/18YSyBWLi_iKH6eskCUq6cltLqQMz1ZhX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8db5379-17c5-44f7-8314-fb362b84f304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            country  product season\n",
      "0           Somalia    Maize   Deyr\n",
      "21          Somalia    Maize     Gu\n",
      "43          Somalia  Sorghum   Deyr\n",
      "64          Somalia  Sorghum     Gu\n",
      "9117         Malawi    Maize   Main\n",
      "9151         Malawi  Sorghum   Main\n",
      "9174         Malawi    Wheat   Main\n",
      "13743         Kenya    Maize   Long\n",
      "13851         Kenya    Maize  Short\n",
      "13944         Kenya  Sorghum   Long\n",
      "13947         Kenya  Sorghum  Short\n",
      "22719  Burkina Faso    Maize   Main\n",
      "22754  Burkina Faso  Sorghum   Main\n",
      "./public/grain_yield_africa.csv is saved.\n",
      "./public/grain_pay_africa.csv is saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dlee/opt/anaconda3/envs/chafs/lib/python3.8/site-packages/geopandas/io/file.py:299: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  pd.Int64Index,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./public/admin_africa.shp is saved.\n"
     ]
    }
   ],
   "source": [
    "shape = gpd.read_file('./data/shapefile/adm_current.shp')\n",
    "df = pd.read_hdf('./data/crop/adm_crop_production_ALL.hdf')\n",
    "df = df.merge(shape[['FNID','ADMIN0','ADMIN1','ADMIN2']], left_on='fnid', right_on='FNID')\n",
    "df = df.rename(columns={'ADMIN1':'admin1','ADMIN2':'admin2','season_name':'season'})\n",
    "df = df[['fnid','country','admin1','admin2','product','season','harvest_end','year','indicator','value']]\n",
    "df = df[\n",
    "    (df['season'].isin(['Gu','Deyr','Long','Short','Main'])) &\n",
    "    (df['product'].isin(['Maize','Wheat','Sorghum']))\n",
    "].reset_index(drop=True)\n",
    "cps = df[['country','product','season']].drop_duplicates()\n",
    "print(cps)\n",
    "df_yield = df[df['indicator'] == 'yield']\n",
    "df_yield = df_yield.pivot_table(index=['fnid','country','admin1','admin2','product','season','harvest_end','indicator'], columns='year', values='value')\n",
    "df_yield = df_yield.astype(np.float32).round(3)\n",
    "fn_out = './public/grain_yield_africa.csv'\n",
    "df_yield.to_csv(fn_out)\n",
    "print(\"%s is saved.\" % fn_out)\n",
    "fn_out = './public/grain_pay_africa.csv'\n",
    "df.to_csv(fn_out)\n",
    "print(\"%s is saved.\" % fn_out)\n",
    "shape.to_file('./public/admin_africa.shp')\n",
    "print('./public/admin_africa.shp is saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc6de58-20dd-4953-bc0b-30594ef192af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
