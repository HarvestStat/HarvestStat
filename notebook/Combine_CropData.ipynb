{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff9b9ec5-d7b5-47f9-ad7c-e1944787daf8",
   "metadata": {},
   "source": [
    "# Combining the processed crop data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "600a2d45-a0c1-4195-aea9-29a2612caf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import seaborn as sns\n",
    "from tools import get_product_name_dict\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b369e5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Country to be combined ==================================== #\n",
    "# [Afghanistan and Yemen] will be excluded for the HarvestStat paper data\n",
    "country_code_list = [\n",
    "    'AF','AO','BF','BI','BJ','CD','CF','CM','ET','GN','KE','LR','LS','MG','ML','MR','MW','MZ',\n",
    "    'NE','NG','RW','SD','SL','SN','SO','SS','TD','TG','TZ','UG','ZA','ZM','ZW','YE',\n",
    "]\n",
    "# =========================================================== #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89731dec-8303-475a-839a-e64bd8ad6d16",
   "metadata": {},
   "source": [
    "## Combine the processed crop data and shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cc60254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cocoyam ['Kenya' 'Tanzania, United Republic of']\n",
      "Pigeon Peas ['Sudan']\n",
      "Avocado (Hass) ['Ethiopia']\n",
      "Cooking Banana ['Burundi' 'DRC' 'Cameroon' 'Rwanda' 'Uganda']\n",
      "Total 65 products are selected to remove over 13 countries.\n",
      "BI: Cassava (non-bitter), Rice (not husked)\n",
      "BJ: Colocynth, Green Pea\n",
      "ET: Beans (Red), Enset, Gibto, Grass Pea, Kabuli Chick Pea, Safflower Seed, Swiss Chard, Vetch, Beans (mixed)\n",
      "LS: Barley\n",
      "MG: African oil palm nut, Artichoke, Broccoli, Clove, Cocoa, Fibers, Fodder crop, Other stem vegetables, Pulses (dry), Strawberry, Vanilla\n",
      "MW: Beans (Pinto), Wheat\n",
      "MZ: Beans (Lima), Beans (Rosecoco), Cashew (unshelled), Groundnuts (In Shell, Large), Groundnuts (In Shell, Small), Macadamia, Other root/tuber vegetable, Spanish Peanut, Sweet Potatoes (Non-Orange), Sweet Potatoes (Orange), Virginia Peanut\n",
      "NE: Anise, Basil, Coriander, Gourd, Henna, Tigernut\n",
      "NG: Groundnuts (Without Shell)\n",
      "RW: Cauliflowers, Champignon, Leeks, Spinach\n",
      "SD: Cotton (Egyptian), Pigeon Peas\n",
      "ZA: Canola Seed\n",
      "YE: Almond, Apple, Apricot, Beans (Green), Beans (Red Kidney), Cantaloupe, Date, Fig, Mandarin Orange, Peach, Pomegranate, Quince, Vegetables\n"
     ]
    }
   ],
   "source": [
    "# Product mapping and selection ============================= #\n",
    "container = []\n",
    "for country_code in country_code_list:\n",
    "    df = pd.read_csv('../data/crop/adm_crop_production_%s.csv' % country_code, index_col=0)\n",
    "    container.append(df)\n",
    "df = pd.concat(container, axis=0).reset_index(drop=True)\n",
    "# Change country name\n",
    "df['country'] = df['country'].replace({'Congo, The Democratic Republic of the': 'DRC'})\n",
    "# Check all product names are in the dictionary\n",
    "product_name_dict = get_product_name_dict()     # Predefined product name mapping\n",
    "product_diff = set(df['product'].unique()) - set(product_name_dict.values())\n",
    "if len(product_diff) > 0:\n",
    "    for p in product_diff:\n",
    "        country = df[df['product'] == p]['country'].unique()\n",
    "        print(p, country)\n",
    "# Select products to remove with rules:\n",
    "# 1. The product is only produced in a single country.\n",
    "# 2. The product has less than 200 data points.\n",
    "cp_count = df[df['indicator'] == 'production'].pivot_table(index='country_code',columns='product', values='value', aggfunc='count').fillna(0).astype(int)\n",
    "product_single_country = cp_count.columns[(np.sum(cp_count > 0) == 1)]\n",
    "product_low_data_points = cp_count.columns[cp_count.sum(0) < 200]\n",
    "product_remove = list(set(product_single_country) & set(product_low_data_points))\n",
    "cp_remove = cp_count.loc[:, cp_count.columns.isin(product_remove)]\n",
    "cp_remove = cp_remove[cp_remove.sum(1) > 0]\n",
    "product_remove_dict = {index: cp_remove.columns[row > 0].tolist() for index, row in cp_remove.iterrows()}\n",
    "# Manually define products to remove or keep ---------------- #\n",
    "product_keep = []\n",
    "product_remove_country = {\n",
    "    'ET':['Beans (mixed)'],\n",
    "    'BJ':['Green Pea'],\n",
    "    'LS':['Barley'], # too low production compared to FAOSTAT\n",
    "    'MW':['Wheat'], # too many missing units (MPE is -87% compared to FAOSTAT)\n",
    "}\n",
    "product_keep_country = {\n",
    "    'ZA': ['Maize (Yellow)']\n",
    "}\n",
    "combined_remove_dict = {}\n",
    "for country in country_code_list:\n",
    "    if country not in product_remove_dict:\n",
    "        products = []\n",
    "    else:\n",
    "        products = product_remove_dict[country]\n",
    "    if country in product_remove_country:\n",
    "        products += product_remove_country[country]\n",
    "    if country in product_keep_country:\n",
    "        products = list(set(products) - set(product_keep_country[country]))\n",
    "    if len(products) > 0:\n",
    "        combined_remove_dict[country] = products\n",
    "# ----------------------------------------------------------- #\n",
    "num_country = len(combined_remove_dict.keys())\n",
    "num_product = len(set([p for ps in combined_remove_dict.values() for p in ps]))\n",
    "print('Total %02d products are selected to remove over %02d countries.' % (num_product, num_country))\n",
    "for country, products in combined_remove_dict.items():\n",
    "    print('%s: %s' % (country, ', '.join(products)))\n",
    "# =========================================================== #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d6815a3-8f53-4d0f-b366-dc85fc42579c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge crop data =========================================== #\n",
    "container = []\n",
    "for country_code in country_code_list:\n",
    "    df = pd.read_csv('../data/crop/adm_crop_production_%s.csv' % country_code, index_col=0)\n",
    "    # A bug may set entries without QC flags, which should be 0, to NaN. Find these and replace them with a QC flag of 0\n",
    "    df.loc[np.isnan(df.QC_flag),'QC_flag'] = 0\n",
    "    # Remove the selected products per country\n",
    "    if country_code in combined_remove_dict.keys():\n",
    "        df = df.loc[~(np.isin(df['product'],combined_remove_dict[country_code]))]\n",
    "    # Pivot table\n",
    "    cols_raw = df.columns\n",
    "    cols = [\n",
    "        'fnid', 'country', 'country_code', 'admin_1', 'admin_2', 'name',   \n",
    "        'season_name', 'planting_year', 'planting_month',\n",
    "        'harvest_year', 'harvest_month', 'crop_production_system', 'QC_flag'\n",
    "    ]\n",
    "    area = df[df['indicator'] == 'area'].pivot_table(index = cols, columns = 'product', values='value', aggfunc='sum')\n",
    "    prod = df[df['indicator'] == 'production'].pivot_table(index = cols, columns = 'product', values='value', aggfunc='sum')\n",
    "    crop = prod/area\n",
    "    area = area.stack().rename('value').reset_index()\n",
    "    area['indicator'] = 'area'\n",
    "    prod = prod.stack().rename('value').reset_index()\n",
    "    prod['indicator'] = 'production'\n",
    "    crop = crop.stack().rename('value').reset_index()\n",
    "    crop['indicator'] = 'yield'\n",
    "    df = pd.concat([area, prod, crop])[cols_raw]\n",
    "    # Reset QC flags (which were aggregated) to be 0/1\n",
    "    df.loc[(df.QC_flag!=0)]['QC_flag']=1\n",
    "    container.append(df)\n",
    "df = pd.concat(container, axis=0).reset_index(drop=True)\n",
    "# Change country name\n",
    "df['country'] = df['country'].replace({'Congo, The Democratic Republic of the': 'DRC'})\n",
    "# Pivot table\n",
    "ind = ['fnid','country','country_code','admin_1','admin_2','product','season_name','planting_year','planting_month','harvest_year','harvest_month','crop_production_system','QC_flag']\n",
    "pivot = df.pivot_table(index = ind, columns = 'indicator', values='value', aggfunc='count')\n",
    "assert pivot.max().max() == 1 # checking duplicates\n",
    "pivot = df.pivot_table(index = ind, columns = 'indicator', values='value').reset_index()\n",
    "pivot = pivot.sort_values(ind)\n",
    "pivot.columns.name = None\n",
    "# =========================================================== #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbc49cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional QC from the comparison with FAOSTAT ============ #\n",
    "# Collect indices to drop in a list\n",
    "indices_to_drop = []\n",
    "# Remove AO-Sorghum data before 2000; outliers\n",
    "indices_to_drop.extend(pivot[(pivot['country_code']=='AO') & (pivot['product']=='Sorghum') & (pivot['harvest_year']<2000)].index)\n",
    "# Remove MW-Wheat data in 2020; outliers\n",
    "indices_to_drop.extend(pivot[(pivot['country_code']=='MW') & (pivot['product']=='Wheat') & (pivot['harvest_year']==2020)].index)\n",
    "# Remove ML-Sorghum data in 2010; outliers\n",
    "indices_to_drop.extend(pivot[(pivot['country_code']=='ML') & (pivot['product']=='Sorghum') & (pivot['harvest_year']==2010)].index)\n",
    "# Remove CM-Millet data before 2005; outliers\n",
    "indices_to_drop.extend(pivot[(pivot['country_code']=='CM') & (pivot['product']=='Millet') & (pivot['harvest_year']<2005)].index)\n",
    "# Remove RW-Wheat data in 2009 and 2010; outliers)\n",
    "indices_to_drop.extend(pivot[(pivot['country_code']=='RW') & (pivot['product']=='Wheat') & (pivot['harvest_year'].isin([2009,2010]))].index)\n",
    "# Remove CD-Maize data in 2015 and 2016; outliers\n",
    "indices_to_drop.extend(pivot[(pivot['country_code']=='CD') & (pivot['product']=='Maize') & (pivot['harvest_year'].isin([2015,2016]))].index)\n",
    "# Remove CD-Rice data in 2013; outliers\n",
    "indices_to_drop.extend(pivot[(pivot['country_code']=='CD') & (pivot['product']=='Rice') & (pivot['harvest_year']==2013)].index)\n",
    "# Drop indices\n",
    "pivot = pivot.drop(index=indices_to_drop).reset_index(drop=True)\n",
    "# MR-Millet Annual season year shift (year -1)\n",
    "pivot.loc[(pivot['country_code']=='MR') & (pivot['product']=='Millet') & (pivot['season_name']=='Annual'), 'harvest_year'] -= 1\n",
    "pivot.loc[(pivot['country_code']=='MR') & (pivot['product']=='Millet') & (pivot['season_name']=='Annual'), 'planting_year'] -= 1\n",
    "# TG data shift (year -1) all crops of Main season before 2009\n",
    "pivot.loc[(pivot['country_code']=='TG') & (pivot['season_name']=='Main') & (pivot['harvest_year']<2009), 'harvest_year'] -= 1\n",
    "pivot.loc[(pivot['country_code']=='TG') & (pivot['season_name']=='Main') & (pivot['planting_year']<2009), 'planting_year'] -= 1\n",
    "# =========================================================== #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7912f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the shapefiles ====================================== #\n",
    "path_dir = '../data/shapefile/fewsnet/'\n",
    "shape_fn_list = []\n",
    "# - Asia\n",
    "shape_fn_list.append(os.path.join(path_dir, 'AF_Admin1_2017.shp')) # Afghanistan Admin1 in 2017\n",
    "shape_fn_list.append(os.path.join(path_dir, 'YE_Admin1_2014.shp')) # Yemen Admin1 in 2014\n",
    "# - East Africa\n",
    "shape_fn_list.append(os.path.join(path_dir, 'BI_Admin1_1998.shp')) # Brundi Admin1 in 1998\n",
    "shape_fn_list.append(os.path.join(path_dir, 'ET_Admin2_2019.shp')) # Ethiopia Admin2 in 2019\n",
    "shape_fn_list.append(os.path.join(path_dir, 'KE_Admin1_2009.shp')) # Kenya Admin1 in 2009\n",
    "shape_fn_list.append(os.path.join(path_dir, 'KE_Admin1_2013.shp')) # Kenya Admin1 in 2013\n",
    "shape_fn_list.append(os.path.join(path_dir, 'SO_Admin1_1990.shp')) # Somalia Admin1 in 1990\n",
    "shape_fn_list.append(os.path.join(path_dir, 'SO_Admin2_1990.shp')) # Somalia Admin2 in 1990\n",
    "shape_fn_list.append(os.path.join(path_dir, 'MG_Admin2_2009.shp')) # Madagascar Admin2 in 2009\n",
    "shape_fn_list.append(os.path.join(path_dir, 'MW_Admin2_2018.shp')) # Malawi Admin2 in 2018\n",
    "shape_fn_list.append(os.path.join(path_dir, 'MZ_Admin1_2021.shp')) # Mozambique Admin1 in 2013\n",
    "shape_fn_list.append(os.path.join(path_dir, 'RW_Admin2_2006.shp')) # Rwanda Admin2 in 2006\n",
    "shape_fn_list.append(os.path.join(path_dir, 'SS_Admin1_2011.shp')) # South Sudan Admin1 in 2011\n",
    "shape_fn_list.append(os.path.join(path_dir, 'TZ_Admin1_2012.shp')) # Tanzania Admin1 in 2012\n",
    "shape_fn_list.append(os.path.join(path_dir, 'UG_Admin2_2007.shp')) # Uganda Admin2 in 2007\n",
    "shape_fn_list.append(os.path.join(path_dir, 'ZM_Admin2_2011.shp')) # Zambia Admin2 in 2011\n",
    "shape_fn_list.append(os.path.join(path_dir, 'ZW_Admin1_2011.shp')) # Zimbabwe Admin1 in 2011\n",
    "shape_fn_list.append(os.path.join(path_dir, 'ZW_Admin2_2011.shp')) # Zimbabwe Admin2 in 2011\n",
    "# - Central Africa\n",
    "shape_fn_list.append(os.path.join(path_dir, 'AO_Admin1_2008.shp')) # Angola Admin1 in 2008\n",
    "shape_fn_list.append(os.path.join(path_dir, 'CM_Admin1_2008.shp')) # Cameroon Admin1 in 2008\n",
    "shape_fn_list.append(os.path.join(path_dir, 'CF_Admin1_2003.shp')) # Central African Republic Admin1 in 2003\n",
    "shape_fn_list.append(os.path.join(path_dir, 'TD_Admin1_2012.shp')) # Chad Admin1 in 2012\n",
    "shape_fn_list.append(os.path.join(path_dir, 'CD_Admin1_2015.shp')) # DRC Admin1 in 2015\n",
    "# - North Africa\n",
    "shape_fn_list.append(os.path.join(path_dir, 'MR_Admin1_1990.shp')) # Mauritania Admin1 in 1990\n",
    "shape_fn_list.append(os.path.join(path_dir, 'SD_Admin1_2013.shp')) # Sudan Admin1 in 2013\n",
    "# - West Africa\n",
    "shape_fn_list.append(os.path.join(path_dir, 'BJ_Admin2_2015.shp')) # Benin Admin2 in 2015\n",
    "shape_fn_list.append(os.path.join(path_dir, 'BF_Admin2_2020.shp')) # Burkina Faso Admin2 in 2020\n",
    "shape_fn_list.append(os.path.join(path_dir, 'CM_Admin2_2008.shp')) # Cameroon Admin2 in 2008\n",
    "shape_fn_list.append(os.path.join(path_dir, 'GN_Admin2_1990.shp')) # Guinea Admin2 in 1990\n",
    "shape_fn_list.append(os.path.join(path_dir, 'LR_Admin1_2008.shp')) # Liberia Admin1 in 2008\n",
    "shape_fn_list.append(os.path.join(path_dir, 'ML_Admin1_2016.shp')) # Mali Admin1 in 2016\n",
    "shape_fn_list.append(os.path.join(path_dir, 'NE_Admin2_2012.shp')) # Niger Admin2 in 2012\n",
    "shape_fn_list.append(os.path.join(path_dir, 'NG_Admin1_1996.shp')) # Nigeria Admin1 in 1996\n",
    "shape_fn_list.append(os.path.join(path_dir, 'SN_Admin2_2008.shp')) # Senegal Admin2 in 2008\n",
    "shape_fn_list.append(os.path.join(path_dir, 'SL_Admin2_1960.shp')) # Sierra Leone Admin2 in 1960\n",
    "shape_fn_list.append(os.path.join(path_dir, 'TG_Admin2_2009.shp')) # Togo Admin2 in 2009\n",
    "# - Southern Africa\n",
    "shape_fn_list.append(os.path.join(path_dir, 'LS_Admin1_1980.shp')) # Lesotho Admin1 in 1980\n",
    "shape_fn_list.append(os.path.join(path_dir, 'ZA_Admin1_1994.shp')) # South Africa Admin1 in 1994\n",
    "# Merge the shapefiles\n",
    "shape = pd.concat([gpd.read_file(fn).to_crs(epsg=4326) for fn in shape_fn_list], axis=0).reset_index(drop=True)\n",
    "shape['COUNTRY_ISO'] = shape['FNID'].apply(lambda x: x[:2])\n",
    "shape = shape[['FNID','COUNTRY_ISO','ADMIN0','ADMIN1','ADMIN2','geometry']]\n",
    "shape = shape.sort_values('FNID').reset_index(drop=True)\n",
    "# Check all fnid in the crop data are in the shapefile\n",
    "fnid_diff = set(pivot['fnid'].unique()) - set(shape['FNID'].unique())\n",
    "assert len(fnid_diff) == 0\n",
    "# Manual correction\n",
    "# Drop a row if FNID is \"ZW2011A21503\" and ADMIN2 is \"Hwange Urban\"\n",
    "shape = shape[~((shape['FNID'] == 'ZW2011A21503') & (shape['ADMIN2'] == 'Hwange Urban'))]\n",
    "assert len(shape['FNID'].unique()) == shape.shape[0]\n",
    "# Reduce to designated countries\n",
    "if True: shape = shape[shape['COUNTRY_ISO'].isin(country_code_list)].reset_index(drop=True)\n",
    "# Create country boundary (Admin0)\n",
    "admin0 = shape.copy(deep=True)\n",
    "admin0['ADMIN_CODE'] = admin0['FNID'].apply(lambda x: x[:8])\n",
    "admin0 = admin0.to_crs(epsg=3857)\n",
    "admin0['geometry'] = admin0['geometry'].buffer(200)\n",
    "admin0 = admin0.dissolve(by='ADMIN_CODE')\n",
    "admin0['geometry'] = admin0['geometry'].buffer(-200)\n",
    "admin0 = admin0.loc[~admin0.index.isin(['KE2009A1','SO1990A1','ZW2011A1']),:]\n",
    "admin0[['ADMIN1','ADMIN2']] = ''\n",
    "admin0['FNID'] = admin0.index\n",
    "admin0['FNID'] = admin0['FNID'].apply(lambda x: x[:-1]+'0')\n",
    "admin0 = admin0.reset_index(drop=True)\n",
    "admin0 = admin0.to_crs(epsg=4326)\n",
    "# Merge\n",
    "shape = pd.concat([admin0, shape], ignore_index=True).reset_index(drop=True)\n",
    "shape = shape[['FNID','ADMIN0','ADMIN1','ADMIN2','geometry']]\n",
    "shape = shape.sort_values(by=['FNID']).reset_index(drop=True)\n",
    "# Change country_name\n",
    "shape['ADMIN0'] = shape['ADMIN0'].replace({'Democratic Republic of the Congo': 'DRC'})\n",
    "# =========================================================== #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bd8e6c-3924-42af-b3c3-f6fb5e656d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data (All-purpose) =============================== #\n",
    "fn_out = '../public/hvstat_data.csv'\n",
    "pivot.to_csv(fn_out, index=False)\n",
    "print('%s is saved (%.2f MB).' % (fn_out, os.path.getsize(fn_out)/1024**2))\n",
    "# Simplify the shapefile\n",
    "shape_simplified = shape.copy()\n",
    "shape_simplified.geometry = shape_simplified.geometry.simplify(0.001)\n",
    "fn_out = '../public/hvstat_boundary.gpkg'\n",
    "shape_simplified.to_file(fn_out, driver='GPKG')\n",
    "print('%s is saved (%.2f MB).' % (fn_out, os.path.getsize(fn_out)/1024**2))\n",
    "# =========================================================== #\n",
    "\n",
    "# Save the data (Paper version) ============================= #\n",
    "# Exclude countries outside of Africa\n",
    "pivot = pivot[~pivot['country_code'].isin(['AF','YE'])].reset_index(drop=True)\n",
    "# Version number\n",
    "version = '1.0'\n",
    "fn_out = f'../public/hvstat_data_v{version}.csv'\n",
    "pivot.to_csv(fn_out, index=False)\n",
    "print('%s is saved (%.2f MB).' % (fn_out, os.path.getsize(fn_out)/1024**2))\n",
    "fn_out = f'../public/hvstat_boundary_v{version}.gpkg'\n",
    "# Select boundaries only shown in the data\n",
    "admin_level = pivot['fnid'].apply(lambda x: x[:8]).unique()\n",
    "shape_simplified = shape_simplified[shape_simplified['FNID'].apply(lambda x: x[:8]).isin(admin_level)].reset_index(drop=True)\n",
    "shape_simplified.to_file(fn_out, driver='GPKG')\n",
    "print('%s is saved (%.2f MB).' % (fn_out, os.path.getsize(fn_out)/1024**2))\n",
    "# =========================================================== #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd962b84-ce59-44cc-973b-477f81ee05c7",
   "metadata": {},
   "source": [
    "## Summary of \"HarvestStat_v1.0_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d899288-7aee-40da-b5d4-ed69e8b77002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# version = '1.0'\n",
    "# shape = gpd.read_file(f'../public/hvstat_boundary_v{version}.gpkg')\n",
    "# shape = shape[shape['FNID'].apply(lambda x: x[-2:] != 'A0')].reset_index(drop=True)\n",
    "# df = pd.read_csv(f'../public/hvstat_data_v{version}.csv')\n",
    "# df = df.merge(shape[['FNID','ADMIN0','ADMIN1','ADMIN2']], left_on='fnid', right_on='FNID')\n",
    "# df = df.rename(columns={'ADMIN1':'admin1','ADMIN2':'admin2','season_name':'season'})\n",
    "# df = df[['fnid','country','admin1','admin2','product','season','harvest_month','harvest_year','production']]\n",
    "# cps = df[['country','product','season']].drop_duplicates().reset_index(drop=True)\n",
    "# df['admin'] = df['fnid'].apply(lambda x: x[2:8])\n",
    "# table = pd.DataFrame(\n",
    "#     index=pd.MultiIndex.from_frame(df[['country','admin','season']].drop_duplicates()),\n",
    "#     columns= cps['product'].unique(),\n",
    "#     data = '-'\n",
    "# ).rename_axis(columns='product')\n",
    "# for i, (country_name, product_name, season_name) in cps.iterrows():\n",
    "#     fnids_country = shape.loc[shape['ADMIN0'] == country_name, 'FNID']\n",
    "#     sub = df[\n",
    "#         (df['country'] == country_name) &\n",
    "#         (df['product'] == product_name) &\n",
    "#         (df['season'] == season_name)\n",
    "#     ]\n",
    "#     if sub.shape[0] > 0:\n",
    "#         count = sub.pivot_table(index='harvest_year', columns='fnid', values='production', aggfunc='count', fill_value=0)\n",
    "#         mean_count = count.sum().mean()\n",
    "#         string = '%d (%d/%d)' %  (mean_count, count.shape[1], len(fnids_country))\n",
    "#     else:\n",
    "#         string = '-'\n",
    "#     table.loc[pd.IndexSlice[country_name,:,season_name],product_name] = string\n",
    "# print('Mean record years (recorded districts / total districts)')\n",
    "# print(table.shape)\n",
    "# table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31733794-114a-41ea-8d6d-e9be59f4f5e6",
   "metadata": {},
   "source": [
    "## Map of processed countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d866b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
    "set_matplotlib_formats('retina')\n",
    "plt.rcParams['font.sans-serif'] = 'Arial'\n",
    "\n",
    "# Little touch on world boundary ---------------------------- #\n",
    "world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "somalia = world[world['name'].isin(['Somalia', 'Somaliland'])].dissolve()\n",
    "world = pd.concat([world[~world['name'].isin(['Somalia', 'Somaliland'])], somalia], axis=0)\n",
    "world.replace(\n",
    "    {   'Tanzania':'Tanzania, United Republic of',\n",
    "        'Dem. Rep. Congo':'DRC',\n",
    "        'Central African Rep.': 'Central African Republic',\n",
    "        'S. Sudan':'South Sudan',\n",
    "    }, inplace=True\n",
    ")\n",
    "df = pd.read_csv('../public/hvstat_data.csv')\n",
    "# ----------------------------------------------------------- #\n",
    "df['admin'] = df['fnid'].apply(lambda x: x[7])\n",
    "country_processed = df[['country','admin']].drop_duplicates()\n",
    "map_processed = world.merge(country_processed, left_on='name', right_on='country', how='inner')\n",
    "assert len(map_processed['country'].dropna().unique()) == len(df['country'].unique())\n",
    "map_processed['admin'] = map_processed['admin'].replace({'1':'Admin-1 level', '2':'Admin-2 level'})\n",
    "# Plotting\n",
    "mapdata = map_processed.copy().to_crs('esri:54030')\n",
    "world = world.to_crs('esri:54030')\n",
    "sns.set_style(\"white\", {'axes.linewidth': 1, 'grid.color': 'black'})\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(10,5), facecolor='w')\n",
    "ax.set_axis_off()\n",
    "ax.set_aspect('equal')\n",
    "ax.axis([-12000000, 14000000, -5500000, 7500000])\n",
    "world.plot(ax=ax, color='lightgrey')\n",
    "mapdata.plot(ax=ax, column='admin',linewidth=1.5, edgecolor='#505050', zorder=2,\n",
    "            categorical=True, legend=True,\n",
    "            legend_kwds={\n",
    "                'loc': 'lower right', \n",
    "                'bbox_to_anchor':(0.825,0), \n",
    "                'frameon':False,\n",
    "                'ncol':1,\n",
    "                'fontsize':13\n",
    "            },\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig('../docs/current_status_map.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce539b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_processed.groupby('admin')['country'].count()\n",
    "# Group by admin level, and aggregate texts of each country. When grouping, sort countries by alphabet order.\n",
    "country_list = country_processed.sort_values('country')\n",
    "country_list = country_list.groupby('admin')['country'].apply(lambda x: ', '.join(x)).reset_index()\n",
    "for i, row in country_list.iterrows():\n",
    "    print('Admin', row['admin'], ':', sum(country_processed['admin'] == row['admin']), 'countries')\n",
    "    print(row['country'])\n",
    "    print('')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
